"""
Registration C++ Wrapper

ë³µì¡í•œ ê³„ì¸µì  ì ì‘ íƒìƒ‰ì„ ìœ„í•œ C++ ë˜í¼
C++ êµ¬í˜„ì´ ì‚¬ìš© ê°€ëŠ¥í•  ë•ŒëŠ” C++ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê³ ,
ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Python êµ¬í˜„ìœ¼ë¡œ Fallbackí•˜ëŠ” ë˜í¼
"""

import numpy as np
from typing import Dict, List, Union, Tuple, Any, Optional
import warnings

# C++ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œë„
try:
    from higgsr_ros.core import higgsr_core_cpp
    CPP_AVAILABLE = True
except ImportError:
    higgsr_core_cpp = None
    CPP_AVAILABLE = False

# Python êµ¬í˜„ ì„í¬íŠ¸ (Fallbackìš©)
from higgsr_ros.core.registration import (
    hierarchical_adaptive_search as hierarchical_adaptive_search_python,
    count_correspondences_kdtree as count_correspondences_kdtree_python,
    select_diverse_candidates as select_diverse_candidates_python
)


def _validate_hierarchical_search_inputs(
    global_map_keypoints: np.ndarray,
    live_scan_keypoints: np.ndarray,
    initial_map_x_edges: np.ndarray,
    initial_map_y_edges: np.ndarray,
    level_configs: List[Dict[str, Any]]
) -> None:
    """
    ê³„ì¸µì  íƒìƒ‰ ì…ë ¥ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
    
    Args:
        global_map_keypoints: ê¸€ë¡œë²Œ ë§µ í‚¤í¬ì¸íŠ¸ (N x 2)
        live_scan_keypoints: í˜„ì¬ ìŠ¤ìº” í‚¤í¬ì¸íŠ¸ (M x 2)
        initial_map_x_edges: ì´ˆê¸° ë§µ X ê²½ê³„ê°’
        initial_map_y_edges: ì´ˆê¸° ë§µ Y ê²½ê³„ê°’
        level_configs: ë ˆë²¨ ì„¤ì • ë¦¬ìŠ¤íŠ¸
        
    Raises:
        TypeError: íƒ€ì…ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ ê²½ìš°
        ValueError: ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        AttributeError: í•„ìˆ˜ ì†ì„±ì´ ì—†ëŠ” ê²½ìš°
    """
    # íƒ€ì… ê²€ì¦
    if not isinstance(global_map_keypoints, np.ndarray):
        raise TypeError("global_map_keypoints must be numpy.ndarray")
    if not isinstance(live_scan_keypoints, np.ndarray):
        raise TypeError("live_scan_keypoints must be numpy.ndarray")
    if not isinstance(initial_map_x_edges, np.ndarray):
        raise TypeError("initial_map_x_edges must be numpy.ndarray")
    if not isinstance(initial_map_y_edges, np.ndarray):
        raise TypeError("initial_map_y_edges must be numpy.ndarray")
    if not isinstance(level_configs, list):
        raise TypeError("level_configs must be list")
    
    # í˜•íƒœ ê²€ì¦
    if global_map_keypoints.ndim != 2 or global_map_keypoints.shape[1] != 2:
        raise ValueError("global_map_keypoints must be N x 2 array")
    if live_scan_keypoints.ndim != 2 or live_scan_keypoints.shape[1] != 2:
        raise ValueError("live_scan_keypoints must be M x 2 array")
    if initial_map_x_edges.ndim != 1:
        raise ValueError("initial_map_x_edges must be 1-dimensional")
    if initial_map_y_edges.ndim != 1:
        raise ValueError("initial_map_y_edges must be 1-dimensional")
    
    # í¬ê¸° ê²€ì¦
    if global_map_keypoints.size == 0:
        raise ValueError("global_map_keypoints cannot be empty")
    if live_scan_keypoints.size == 0:
        raise ValueError("live_scan_keypoints cannot be empty")
    if initial_map_x_edges.size < 2:
        raise ValueError("initial_map_x_edges must have at least 2 elements")
    if initial_map_y_edges.size < 2:
        raise ValueError("initial_map_y_edges must have at least 2 elements")
    if len(level_configs) == 0:
        raise ValueError("level_configs cannot be empty")
    
    # level_configs êµ¬ì¡° ê²€ì¦
    for i, config in enumerate(level_configs):
        if not isinstance(config, dict):
            raise TypeError(f"level_configs[{i}] must be dict")
        
        # í•„ìˆ˜ í‚¤ í™•ì¸
        required_keys = ['grid_division', 'search_area_type', 'tx_ty_search_steps_per_cell']
        for key in required_keys:
            if key not in config:
                raise AttributeError(f"level_configs[{i}] missing required key: {key}")
        
        # íƒ€ì… í™•ì¸
        if not isinstance(config['grid_division'], (list, tuple)):
            raise TypeError(f"level_configs[{i}]['grid_division'] must be list or tuple")
        if len(config['grid_division']) != 2:
            raise ValueError(f"level_configs[{i}]['grid_division'] must have 2 elements")
        if not all(isinstance(x, int) and x > 0 for x in config['grid_division']):
            raise ValueError(f"level_configs[{i}]['grid_division'] must contain positive integers")
        
        if not isinstance(config['search_area_type'], str):
            raise TypeError(f"level_configs[{i}]['search_area_type'] must be string")
        
        if not isinstance(config['tx_ty_search_steps_per_cell'], (list, tuple)):
            raise TypeError(f"level_configs[{i}]['tx_ty_search_steps_per_cell'] must be list or tuple")
        if len(config['tx_ty_search_steps_per_cell']) != 2:
            raise ValueError(f"level_configs[{i}]['tx_ty_search_steps_per_cell'] must have 2 elements")
        if not all(isinstance(x, int) and x > 0 for x in config['tx_ty_search_steps_per_cell']):
            raise ValueError(f"level_configs[{i}]['tx_ty_search_steps_per_cell'] must contain positive integers")
    
    # ê²½ê³„ê°’ ì •ë ¬ í™•ì¸
    if not np.all(np.diff(initial_map_x_edges) > 0):
        raise ValueError("initial_map_x_edges must be in ascending order")
    if not np.all(np.diff(initial_map_y_edges) > 0):
        raise ValueError("initial_map_y_edges must be in ascending order")
    
    # NaN/Inf ê²€ì¦
    if not np.all(np.isfinite(global_map_keypoints)):
        raise ValueError("global_map_keypoints contains non-finite values")
    if not np.all(np.isfinite(live_scan_keypoints)):
        raise ValueError("live_scan_keypoints contains non-finite values")
    if not np.all(np.isfinite(initial_map_x_edges)):
        raise ValueError("initial_map_x_edges contains non-finite values")
    if not np.all(np.isfinite(initial_map_y_edges)):
        raise ValueError("initial_map_y_edges contains non-finite values")


def _convert_result_to_dict(result: Any) -> Dict[str, Union[float, int, bool]]:
    """
    C++ ê²°ê³¼ ê°ì²´ë¥¼ Python dictë¡œ ë³€í™˜
    
    Args:
        result: C++ TransformResult ê°ì²´ ë˜ëŠ” Python dict
        
    Returns:
        Dict: ë³€í™˜ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if isinstance(result, dict):
        return result
    
    # C++ ê°ì²´ì—ì„œ ì†ì„± ì¶”ì¶œ
    try:
        return {
            'tx': float(result.tx),
            'ty': float(result.ty),
            'theta_deg': float(result.theta_deg),
            'score': float(result.score),
            'iterations': int(result.iterations),
            'success': bool(result.success)
        }
    except AttributeError as e:
        raise RuntimeError(f"Invalid result object: {e}")


def hierarchical_adaptive_search_cpp(
    global_map_keypoints: np.ndarray,
    live_scan_keypoints: np.ndarray,
    initial_map_x_edges: np.ndarray,
    initial_map_y_edges: np.ndarray,
    level_configs: List[Dict[str, Any]],
    num_candidates_to_select_per_level: int = 5,
    min_candidate_separation_factor: float = 2.0,
    base_grid_cell_size: float = 1.0,
    num_processes: int = 0,
    use_cpp: bool = True
) -> Dict[str, Union[float, int, bool]]:
    """
    C++ ê°€ì†í™”ëœ ê³„ì¸µì  ì ì‘ íƒìƒ‰ í•¨ìˆ˜
    
    Args:
        global_map_keypoints: ê¸€ë¡œë²Œ ë§µì˜ í‚¤í¬ì¸íŠ¸ë“¤ (N x 2)
        live_scan_keypoints: í˜„ì¬ ìŠ¤ìº”ì˜ í‚¤í¬ì¸íŠ¸ë“¤ (M x 2)
        initial_map_x_edges: ì´ˆê¸° ë§µ X ê²½ê³„ê°’ ë°°ì—´
        initial_map_y_edges: ì´ˆê¸° ë§µ Y ê²½ê³„ê°’ ë°°ì—´
        level_configs: ê° ë ˆë²¨ì˜ íƒìƒ‰ ì„¤ì • ë¦¬ìŠ¤íŠ¸
        num_candidates_to_select_per_level: ë ˆë²¨ë‹¹ ì„ íƒí•  í›„ë³´ ìˆ˜
        min_candidate_separation_factor: ìµœì†Œ í›„ë³´ ë¶„ë¦¬ íŒ©í„°
        base_grid_cell_size: ê¸°ë³¸ ê·¸ë¦¬ë“œ ì…€ í¬ê¸°
        num_processes: ë³‘ë ¬ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (0ì€ ì‹œí€€ì…œ)
        use_cpp: C++ êµ¬í˜„ ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        Dict: ìµœì  ë³€í™˜ ê²°ê³¼
            - tx: X ë°©í–¥ ì´ë™
            - ty: Y ë°©í–¥ ì´ë™
            - theta_deg: íšŒì „ ê°ë„(ë„)
            - score: ë§¤ì¹­ ì ìˆ˜
            - iterations: ìˆ˜í–‰ëœ ë°˜ë³µ íšŸìˆ˜
            - success: ì„±ê³µ ì—¬ë¶€
            
    Raises:
        TypeError: ì…ë ¥ íƒ€ì…ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ ê²½ìš°
        ValueError: ì…ë ¥ ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        RuntimeError: íƒìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    # ì…ë ¥ ìœ íš¨ì„± ê²€ì¦
    _validate_hierarchical_search_inputs(
        global_map_keypoints, live_scan_keypoints,
        initial_map_x_edges, initial_map_y_edges, level_configs
    )
    
    # ì¶”ê°€ íŒŒë¼ë¯¸í„° ê²€ì¦
    if not isinstance(num_candidates_to_select_per_level, int) or num_candidates_to_select_per_level <= 0:
        raise ValueError("num_candidates_to_select_per_level must be positive integer")
    if not isinstance(min_candidate_separation_factor, (int, float)) or min_candidate_separation_factor <= 0:
        raise ValueError("min_candidate_separation_factor must be positive number")
    if not isinstance(base_grid_cell_size, (int, float)) or base_grid_cell_size <= 0:
        raise ValueError("base_grid_cell_size must be positive number")
    if not isinstance(num_processes, int) or num_processes < 0:
        raise ValueError("num_processes must be non-negative integer")
    
    try:
        # C++ êµ¬í˜„ ì‚¬ìš© ì‹œë„
        if use_cpp and CPP_AVAILABLE and higgsr_core_cpp is not None:
            # íƒ€ì… ë³€í™˜
            global_keypoints_double = global_map_keypoints.astype(np.float64, copy=False)
            scan_keypoints_double = live_scan_keypoints.astype(np.float64, copy=False)
            x_edges_double = initial_map_x_edges.astype(np.float64, copy=False)
            y_edges_double = initial_map_y_edges.astype(np.float64, copy=False)
            
            result = higgsr_core_cpp.hierarchical_adaptive_search(
                global_keypoints_double,
                scan_keypoints_double,
                x_edges_double,
                y_edges_double,
                level_configs,
                num_candidates_to_select_per_level,
                min_candidate_separation_factor,
                base_grid_cell_size,
                num_processes
            )
            
            # ê²°ê³¼ ë³€í™˜
            result_dict = _convert_result_to_dict(result)
            
            # ê²°ê³¼ ê²€ì¦
            required_keys = ['tx', 'ty', 'theta_deg', 'score', 'iterations', 'success']
            for key in required_keys:
                if key not in result_dict:
                    raise RuntimeError(f"C++ function returned incomplete result: missing {key}")
            
            return result_dict
            
    except Exception as e:
        if use_cpp:
            # ğŸš¨ ê°•ë ¥í•œ ê²½ê³ ! ì‚¬ìš©ìê°€ C++ì„ ê¸°ëŒ€í–ˆì§€ë§Œ Pythonìœ¼ë¡œ fallbackë¨
            print("=" * 80)
            print("ğŸš¨ğŸš¨ğŸš¨ CRITICAL WARNING: C++ FALLBACK TO PYTHON ğŸš¨ğŸš¨ğŸš¨")
            print("=" * 80)
            print(f"âŒ C++ hierarchical_adaptive_search FAILED!")
            print(f"ğŸ“ Error: {e}")
            print(f"ğŸ”„ FALLING BACK TO PYTHON IMPLEMENTATION")
            print(f"âš ï¸  Performance will be SIGNIFICANTLY SLOWER!")
            print(f"ğŸ’¡ User was expecting C++ but getting Python!")
            print("=" * 80)
            
            # warningsë„ í•¨ê»˜ ë°œìƒ
            warnings.warn(f"ğŸš¨ C++ FAILED, FALLBACK TO PYTHON: {e}", UserWarning, stacklevel=2)
    
    # ğŸ Python êµ¬í˜„ìœ¼ë¡œ Fallback (ì‚¬ìš©ìê°€ ì†ì•˜ì„ ìˆ˜ ìˆìŒ!)
    try:
        result = hierarchical_adaptive_search_python(
            global_map_keypoints,
            live_scan_keypoints,
            initial_map_x_edges,
            initial_map_y_edges,
            level_configs,
            num_candidates_to_select_per_level,
            min_candidate_separation_factor,
            base_grid_cell_size,
            num_processes
        )
        
        # Python ê²°ê³¼ë¥¼ dict í˜•íƒœë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
        if not isinstance(result, dict):
            # Python í•¨ìˆ˜ê°€ íŠœí”Œì´ë‚˜ ë‹¤ë¥¸ í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
            if hasattr(result, '_asdict'):  # namedtupleì¸ ê²½ìš°
                result = result._asdict()
            else:
                raise RuntimeError("Python function returned unexpected result type")
        
        return result
        
    except Exception as e:
        raise RuntimeError(f"Both C++ and Python implementations failed: {e}")


def count_correspondences_kdtree_cpp(
    transformed_keypoints: np.ndarray,
    global_map_keypoints: np.ndarray,
    distance_threshold: float,
    use_cpp: bool = True
) -> int:
    """
    C++ ê°€ì†í™”ëœ KDTree ê¸°ë°˜ ëŒ€ì‘ì  ê³„ì‚° í•¨ìˆ˜
    
    Args:
        transformed_keypoints: ë³€í™˜ëœ í‚¤í¬ì¸íŠ¸ë“¤ (N x 2)
        global_map_keypoints: ê¸€ë¡œë²Œ ë§µ í‚¤í¬ì¸íŠ¸ë“¤ (M x 2)
        distance_threshold: ë§¤ì¹­ ê±°ë¦¬ ì„ê³„ê°’
        use_cpp: C++ êµ¬í˜„ ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        int: ë§¤ì¹­ëœ ëŒ€ì‘ì  ê°œìˆ˜
        
    Raises:
        TypeError: ì…ë ¥ íƒ€ì…ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì€ ê²½ìš°
        ValueError: ì…ë ¥ ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
    """
    # ì…ë ¥ ìœ íš¨ì„± ê²€ì¦
    if not isinstance(transformed_keypoints, np.ndarray):
        raise TypeError("transformed_keypoints must be numpy.ndarray")
    if not isinstance(global_map_keypoints, np.ndarray):
        raise TypeError("global_map_keypoints must be numpy.ndarray")
    if not isinstance(distance_threshold, (int, float)):
        raise TypeError("distance_threshold must be numeric")
    
    if transformed_keypoints.ndim != 2 or transformed_keypoints.shape[1] != 2:
        raise ValueError("transformed_keypoints must be N x 2 array")
    if global_map_keypoints.ndim != 2 or global_map_keypoints.shape[1] != 2:
        raise ValueError("global_map_keypoints must be M x 2 array")
    if distance_threshold <= 0 or not np.isfinite(distance_threshold):
        raise ValueError("distance_threshold must be positive and finite")
    
    # ë¹ˆ ë°°ì—´ ì²˜ë¦¬
    if transformed_keypoints.size == 0 or global_map_keypoints.size == 0:
        return 0
    
    try:
        # C++ êµ¬í˜„ ì‚¬ìš© ì‹œë„
        if use_cpp and CPP_AVAILABLE and higgsr_core_cpp is not None:
            # íƒ€ì… ë³€í™˜
            transformed_double = transformed_keypoints.astype(np.float64, copy=False)
            global_double = global_map_keypoints.astype(np.float64, copy=False)
            
            result = higgsr_core_cpp.count_correspondences_kdtree(
                transformed_double,
                global_double,
                float(distance_threshold)
            )
            
            if not isinstance(result, int) or result < 0:
                raise RuntimeError("C++ function returned invalid correspondence count")
                
            return result
            
    except Exception as e:
        if use_cpp:
            # ğŸš¨ ê°•ë ¥í•œ ê²½ê³ ! ì‚¬ìš©ìê°€ C++ì„ ê¸°ëŒ€í–ˆì§€ë§Œ Pythonìœ¼ë¡œ fallbackë¨
            print("=" * 60)
            print("ğŸš¨ CRITICAL WARNING: C++ FALLBACK TO PYTHON ğŸš¨")
            print("=" * 60)
            print(f"âŒ C++ count_correspondences_kdtree FAILED!")
            print(f"ğŸ“ Error: {e}")
            print(f"ğŸ”„ FALLING BACK TO PYTHON")
            print("=" * 60)
            
            warnings.warn(f"ğŸš¨ C++ FAILED, FALLBACK TO PYTHON: {e}", UserWarning, stacklevel=2)
    
    # ğŸ Python êµ¬í˜„ìœ¼ë¡œ Fallback
    try:
        # Python í•¨ìˆ˜ í˜¸ì¶œì‹œ KDTree ê°ì²´ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
        from scipy.spatial import KDTree
        global_kdtree = KDTree(global_map_keypoints)
        
        result = count_correspondences_kdtree_python(
            transformed_keypoints, global_kdtree, distance_threshold
        )
        
        return int(result)
        
    except Exception as e:
        raise RuntimeError(f"Both C++ and Python implementations failed: {e}")


# í¸ì˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± ìœ ì§€)
def hierarchical_adaptive_search(
    global_map_keypoints: np.ndarray,
    live_scan_keypoints: np.ndarray,
    initial_map_x_edges: np.ndarray,
    initial_map_y_edges: np.ndarray,
    level_configs: List[Dict[str, Any]],
    num_candidates_to_select_per_level: int = 5,
    min_candidate_separation_factor: float = 2.0,
    base_grid_cell_size: float = 1.0,
    num_processes: int = 0
) -> Dict[str, Union[float, int, bool]]:
    """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    return hierarchical_adaptive_search_cpp(
        global_map_keypoints, live_scan_keypoints,
        initial_map_x_edges, initial_map_y_edges, level_configs,
        num_candidates_to_select_per_level, min_candidate_separation_factor,
        base_grid_cell_size, num_processes, use_cpp=True
    )


def count_correspondences_kdtree(
    transformed_keypoints: np.ndarray,
    global_map_kdtree: Any,  # KDTree ê°ì²´ ë˜ëŠ” í‚¤í¬ì¸íŠ¸ ë°°ì—´
    distance_threshold: float
) -> int:
    """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    # KDTree ê°ì²´ì¸ì§€ í‚¤í¬ì¸íŠ¸ ë°°ì—´ì¸ì§€ íŒë‹¨
    if hasattr(global_map_kdtree, 'query'):  # KDTree ê°ì²´
        # KDTreeì—ì„œ ë°ì´í„° ì¶”ì¶œ
        global_map_keypoints = global_map_kdtree.data
    else:  # í‚¤í¬ì¸íŠ¸ ë°°ì—´
        global_map_keypoints = global_map_kdtree
    
    return count_correspondences_kdtree_cpp(
        transformed_keypoints, global_map_keypoints, distance_threshold, use_cpp=True
    )


# TODO: í–¥í›„ ì¶”ê°€ë  ê¸°ëŠ¥ë“¤
# def select_diverse_candidates_cpp(candidates_info, num_to_select, separation_factor, 
#                                  cell_size_x, cell_size_y, map_x_range, map_y_range, use_cpp=True):
#     """ë‹¤ì–‘í•œ í›„ë³´ ì„ íƒ (C++ ê°€ì†í™”)"""
#     pass
#
# def parallel_search_in_super_grids_cpp(global_keypoints, scan_keypoints, config, num_threads, use_cpp=True):
#     """ë³‘ë ¬ ê·¸ë¦¬ë“œ íƒìƒ‰ (OpenMP í™œìš©)"""
#     pass 